Capitolo 3 - Algoritmi e prestazioni

3.1 - Nota introduttiva
Poiché la maggior parte degli algoritmi di machine learning messi a disposizione dalle librerie di Python funzionava solo su attributi numerici,
è stato necessario convertire i valori degli attributi categorici in valori numerici, mantenendo comunque allineate le rispettive conversioni
tra training set e test set.

3.2 - Modalità di valutazione dei risultati
Secondo il regolamento previsto dalla competizione di Kaggle, ad essere valutato era un file csv che presentasse:
	- un'intestazione, contenente la parola "Id" e i nomi di tutte le categorie di crimini in ordine alfabetico;
	- una sequenza di valori rappresentanti l'id dell'istanza, seguita dalle probabilità di appartenenza alle suddette categorie di crimine,
		predette dal modello relativamente al test set fornitoci.
Riportiamo in Figura X.X un esempio di file da sottomettere.

Ogni partecipante poteva sottomettere al massimo 5 prove al giorno, che venivano valutate usando la metrica cosiddetta "multi-class logarithmic loss".
Premesso che ogni crimine era etichettato con una sola vera categoria, questa metrica di valutazione considerava le probabilità predette di tutte le istanze
per ogni categoria fornite nel file csv, secondo la seguente formula:
			FORMULA MULTICLASS LOGLOSS
dove N è il numero di istanza del test set, M è il numero di classi (categorie di crimine), log è il logaritmo naturale, yij vale 1 se l'istanza i
appartiene alla categoria j e vale 0 altrimenti, e pij è la probabilità predetta che l'istanza i appartenza alla categoria j.
Prima di sottomettere una prova abbiamo suddiviso il training set in due parti: i 2/3 delle istanze è stata usata per addestrare il modello e il rimanente
1/3 è stato usato per predire le probabilità. In questo modo abbiamo potuto calcolare il valore della metrica di valutazione sulle probabilità predette
per avere un'idea generale dell'esito della sottomissione.

Nei seguenti paragrafi verranno illustrati gli algoritmi utilizzati per addestrare i modelli e predire le probabilità richieste.

3.3 - Gaussian Naive Bayes
Il primo algoritmo che abbiamo utilizzato è stato il Gaussian Naive Bayes, una particolare implementazione del Naive Bayes che assume una distribuzione
di probabilità gaussiana delle istanze rispetto alla classe. La scelta è stata effettuata sulla base di molteplici fattori, quali la semplicità, l'efficienza
computazionale, l'ingente quantità di dati e l'obiettivo della competizione, ovvero il calcolo di probabilità.
Sfruttando i vari tipi di preprocessing illustrati nel capitolo precedente, sono state fatte diverse prove: la migliore è stata effettuata rimuovendo
gli attributi Address e PdDistrict, scomponendo l'attributo Dates in Season e DailyRange ed elaborando le coordinate X e Y in una griglia 10x10.
Riportiamo di seguito i risultati ottenuti:
	- Accuracy: 0.20843
	- Score: 2.64736
	- Classifica: 859/1387

3.4 - Reti Neurali
Il secondo modello che abbiamo costruito è stato il Multi-Layer Perceptron, classificatore basato su reti neurali completamente configurabile. E' noto però
che l'efficienza computazionale di una rete neurale decresce all'aumentare della sua complessità, perciò per motivi di tempo e di spazio sono state effettuate
poche prove. La migliore è stata effettuata rimuovendo gli attributi Address e PdDistrict, scomponendo l'attributo Dates in Season e DailyRange ed elaborando le
coordinate X e Y in una griglia 10x10. La rete neurale è stata costruita con i seguenti parametri:
	- 100 unità di input di tipo tangentoide;
	- 2 strati nascosti contenenti rispettivamente 100 unità di tipo tangentoide e 100 di tipo sigmoide;
	- 39 unità di output di tipo softmax;
	- learning rate: 0.1;
	- numero di iterazioni di training aggiuntive in seguito alla stabilizzazione dell'errore di validazione: 2;
	- numero di iterazioni necessarie per calibrare i pesi della rete nella discesa del gradiente: 21.
Riportiamo di seguito i risultati ottenuti:
	- Accuracy: 0.23028
	- Score: 2.56269
	- Classifica: 505/1390

3.5 - Voting Classifier
Dai due paragrafi precedenti si può notare come una maggiore complessità del modello porta ad un notevole miglioramento del punteggio di valutazione. Abbiamo 
quindi considerato l'idea di creare un modello che fosse allo stesso tempo complesso e non eccessivamente costoso dal punto di vista temporale e spaziale e che
consentisse una seppur minima configurazione. Il modello migliore che riassumeva tutte queste qualità è stato il Voting Classifier, un classificatore basato
su un sistema di votazione tra più classificatori creati in modo indipendente. Al contrario delle reti neurali, abbiamo dedicato la maggior parte del nostro
tempo ad effettuare prove cambiando vari parametri e tipi di preprocessing: questo è stato possibile grazie all'efficienza computazionale del modello.
Gli algoritmi scelti per il sistema di votazione sono il Gaussian Naive Bayes e gli alberi di decisione (Decision Tree): abbiamo notato come l'assenza del primo
portasse ad un calo delle prestazioni ed abbiamo perciò deciso di tenerlo in ogni prova. Riportiamo di seguito solo le prove che hanno portato notevoli miglioramenti
nel punteggio.
La prima prova è stata effettuata rimuovendo gli attributi Address e PdDistrict, scomponendo l'attributo Dates in Season e DailyRange ed elabotando le coordinate
X e Y in una griglia 100x100. Oltre al Gaussian Naive Bayes, il modello includeva due alberi di decisione aventi rispettivamente i seguenti parametri:
	- criterion: Gini, min_samples_split: 2500;
	- criterion: Gini, max_leaf_nodes: 39
dove criterion è il criterio con cui viene valutata l'impurità di un nodo, min_samples_split è il numero minimo di esempi richiesto per splittare un nodo e
max_leaf_nodes è il numero massimo di nodi che possono comparire come foglie nell'albero.
I risultati ottenuti sono i seguenti:
	- Accuracy: 0.24892
	- Score: 2.52774
	- Classifica: 403/1415
La seconda prova è stata effettuata sostituendo l'attributo Dates in Year, Month, DayOfMonth e Hour ed elaborando le coordinate X e Y in una griglia 100x100.
A differenza della prima prova inoltre è stato assegnato un peso ad ogni modello partecipante alla votazione, in modo che il voto di certi classificatori
avesse maggiore importanza rispetto ad altri. Oltre al Gaussian Naive Bayes avente un peso pari a 2, il modello includeva due alberi di decisione 
aventi rispettivamente i seguenti parametri:
	- criterion: Gini, min_samples_split: 2500, peso: 5;
	- criterion: Gini, min_sampes_leaf: 39, peso: 4
dove min_samples_leaf è il numero minimo di esempi affiché un nodo possa essere considerato foglia.
I risultati ottenuti sono i seguenti:
	- Accuracy: 0.27487
	- Score: 2.47104
	- Classifica: 308/1419
Nelle successive due prove è stato inserito nel sistema di votazione un ulteriore albero di decisione e sono stati eseguiti diversi tipi di preprocessing.
In particolare nella terza prova l'attributo Dates è stato scomposto sia in Season e DailyRange che in Year, Month e Hour, mantenendo dunque tutti i cinque attributi.
Inoltre le coordinate X e Y sono state elaborate in una griglia 100x100 e l'attributo DayOfWeek è stato sostituito dall'attributo Weekend.
Oltre al Gaussian Naive Bayes avente un peso pari a 2, il modello includeva dunque tre alberi di decisione aventi rispettivamente i seguenti parametri:
	- criterion: Gini, min_samples_split: 2500, peso: 5;
	- criterion: Entropy, min_samples_leaf: 39, peso: 4;
	- criterion: Gini, max_depth: 4, peso: 1
dove max_depth è la profondità massima dell'albero.
I risultati ottenuti sono i seguenti:
	- Accuracy: 0.27456
	- Score: 2.43672
	- Classifica: 281/1457
Infine l'ultima prova è stata effettuata scomponendo l'attributo Dates sia in Season e DailyRange che in Year, Month, Hour e Minute, elaborando le coordinate X e Y
in una griglia 100x100 e aggiungendo gli attributi Weekend e isCross, senza rimuovere i relativi attributi DayOfWeek e Address. I modelli partecipanti
alla votazione sono gli stessi della prova precedente, ad eccezione del primo albero di decisione, costruito con il parametro min_samples_split pari a 250.
I risultati ottenuti da questa ultima prova sono i seguenti:
	- Accuracy: 0.30239
	- Score: 2.35771
	- Classifica: 199/1506